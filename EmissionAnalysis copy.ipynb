{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sekcja odczytywania danych, określania typów danych cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def ReadDataFrame(filename:str, sep:str =';', dec_sep:str =',') -> tuple[pd.DataFrame, int]:\n",
    "    \"\"\"Odczytuje plik o nazwie filename i wprowadza dane z pliku do ramki danych.\"\"\"\n",
    "    global dtypes\n",
    "   \n",
    "    Dataset = pd.read_csv(filename,\n",
    "                        sep=sep, dtype = dtypes, decimal = dec_sep) #Wczytaj plik z danymi.\n",
    "\n",
    "    n_rows:int  = Dataset.shape[0] #Liczba wszystkich wierszy w ramce danych\n",
    "\n",
    "    return Dataset, n_rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sekcja statystyki opisowej zmiennych kategorycznych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Częstość występowania  unikatowych klas dla danej zmiennej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateFreqTable(Dataset:pd.DataFrame, CatFeature:str) ->  pd.DataFrame:\n",
    "    \"\"\"Funkcja dla każdej unikatowej klasy z cechy CatFeature wylicza liczbę jej wystapień.\n",
    "    Wynikiem funkcji jest pandowska ramka danych, która zawiera trzy kolumny o nazwach odpowiednio: 'CatFeature', 'CatFeature_coded' oraz 'count'.\n",
    "    Kolumna CatFeature_coded zawiera zakodowane nazwy klas w postaci liczb całkowitych. Taka forma ułatwia odczytywanie etykiet na wykresach.\n",
    "    \"\"\"\n",
    "\n",
    "    FreqTable:pd.DataFrame = Dataset[CatFeature].value_counts(sort = True,) #Stwórz proste podsumowanie częstotliwości występowania klas.\n",
    "\n",
    "    return  FreqTable\n",
    "\n",
    "def PlotBarPlot(FreqTable:pd.Series, CatFeature:str, Showxlabels:bool = False) -> None:\n",
    "    \"\"\"Funkcja rysuje histogram na bazie tabelki histogramowej. \n",
    "    1) FreqTable  - Tabela częstotliwości kategori danej zmiennej kategorycznej\n",
    "    2) CatFeature  - Cecha kategoryczna, której histogram chcemy narysować.\n",
    "    3) Showxlabel - Zmienna typu bool. Jeżeli ustawiona na True, to etykietki osi Ox są wyświetlane.\"\"\"\n",
    "    \n",
    "    plt.figure(figsize = (10,5)) #Stwórz płótno, na którym  będzie rysowany wykres\n",
    " \n",
    "    axes = sns.barplot(x = FreqTable.index, y = FreqTable.values)\n",
    "\n",
    "\n",
    "    axes.set_ylabel(f\"Częstość klasy\") #Ustaw etykietke pionowej osi.\n",
    "\n",
    "    axes.set_xticklabels([]) #Usuń etykiety tyknięć na osi Ox.\n",
    "    axes.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "    axes.set_title(f\"Histogram klas cechy {CatFeature}\") #Ustaw tytuł wykresu.\n",
    "\n",
    "    axes.set_ylim(0, 1.05*np.max(FreqTable))\n",
    "\n",
    "    if Showxlabels == True:\n",
    "        axes.set_xticklabels(labels = FreqTable.index)\n",
    "        \n",
    "\n",
    "\n",
    "def AggregateRarestClasses(Dataset:pd.DataFrame, CatFeature:str, Histogram:pd.Series, q_degree:float = 0.15) -> None:\n",
    "    \"\"\"Klasy, które występują rzadziej niż wartość wskaźnika threshold_frequent, dostaną etykietę \"Other\". Etykietki pozostałych klas nie ulegną zmian.\n",
    "    1) Dataset - oryginalny zestaw danych.\n",
    "    2) CatFeature - Zmienna kategoryczna, której rzadkie klasy chcemy zagregować.\n",
    "    3) Histogram - Histogram cechy CatFeature\n",
    "    4) q_degree  - stopień kwantylu. \n",
    "    Funkcja jedynie modyfikuje zestaw danych, dlatego właśnie nie zwraca żadnej wartości.\"\"\"\n",
    "    frequent_threshold:float = Histogram.quantile(q = q_degree)\n",
    "\n",
    "    Dataset[CatFeature] = Dataset[CatFeature].apply(func = lambda categ: \"Other\" if Histogram[categ] < frequent_threshold else categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeleteFutileColsAndObs(Dataset:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Funkcja usuwa quasi-identyfikator zmienną oraz jedną obserwację, która zawiera klasę, która występuje tylko raz.\"\"\"\n",
    "\n",
    "    Dataset.drop(columns = [\"Model\"], inplace = True)\n",
    "\n",
    "    Dataset = Dataset.query('`Fuel Type` != \"N\"')\n",
    "\n",
    "    return Dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cechy numeryczne ciągłe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Badanie zależności poziomu emisji dwutlenku węgla w zależności od wielkości spalania paliwa na autostradzie i w mieście dla różnych typów paliwa.\n",
    "### Dodatkowo zbadamy współczynniki korelacji między tymi cechami ciągłymi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAndDrawCorrelationMatrix(Dataset:pd.DataFrame, FloatFeatures: list[str]) -> None:\n",
    "    \"\"\"Funkcja wylicza macierz korelaji dla zmiennych z listy FloatFeatures. Ponadto, rysuje tę macierz korelacji na wykresie, aby można\n",
    "    było sobie uzmysłowić relacje między zmiennymi\n",
    "    1) Dataset - oryginalny zbiór danych\n",
    "    2) FloatFeatures  - zmienne ciągłe\"\"\"\n",
    "    CorrMatrix:pd.DataFrame =  Dataset[FloatFeatures].corr(method = \"pearson\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    sns.heatmap(CorrMatrix, annot=True, cmap='magma', vmin=-1, vmax=1)\n",
    "    plt.title('Macierz korelacji dla zmiennych ciągłych')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discretize(Dataset:pd.DataFrame, target_var:str, target_var_discr:str, bins:list[float]) -> None:\n",
    "    \"\"\"Funkcja dokonuje dyskretyzacji (interwalizacji) zmiennej docelowej ciągłej.\n",
    "    1) Dataset - oryginalny zbiór danych.\n",
    "    2) target_var - zmienna docelowa\n",
    "    3) bins - kubełki, które określają granicę  interwałów zmiennej docelowej.\"\"\"\n",
    "    labels = [i for i in range(len(bins)+1)]\n",
    "    bins = [-float(\"inf\")] + bins + [float('inf')]\n",
    "\n",
    "\n",
    "    discretized_feature = pd.cut(x = Dataset[target_var], \n",
    "                                 bins = bins, \n",
    "                                 labels = labels)\n",
    "\n",
    "    Dataset[target_var_discr] = discretized_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NarysujGęstości(Dataset:pd.DataFrame, FloatFeatures:list[str], Condition:str | None = None) -> None:\n",
    "    \"\"\"Ta funkcja rysuje wykresy gęstości prawdopodobieństwa dla zmiennych ciągłych.\n",
    "    1) Dataset - oryginalny zestaw danych.\n",
    "    2) FloatFeatures - zmienne numeryczne\"\"\"\n",
    "\n",
    "    for floatFeature in FloatFeatures:\n",
    "        figure = plt.figure(num = f\"KDE_plot_{floatFeature}\")\n",
    "        axes = figure.add_subplot()\n",
    "\n",
    "        sns.kdeplot(data = Dataset, x = floatFeature, ax = axes, hue = Condition)\n",
    "        axes.set_title(f\"Wykres gęstości prawdopodobieństwa dla zmiennej {floatFeature}\")\n",
    "\n",
    "\n",
    "def NarysujPudełko(Dataset:pd.DataFrame, FloatFeatures:list[str], Condition: str | None = None) -> None:\n",
    "    \"\"\"Ta funkcja rysuje wykresy pudełkowe dla zmiennych ciągłych.\n",
    "    1) Dataset - oryginalny zestaw danych.\n",
    "    2) FloatFeatures - zmienne numeryczne\"\"\"\n",
    "\n",
    "    for floatFeature in FloatFeatures:\n",
    "        figure = plt.figure(num = f\"BOX_plot_{floatFeature}\")\n",
    "        axes = figure.add_subplot()\n",
    "\n",
    "        sns.boxplot(Dataset, x = floatFeature, hue = Condition)\n",
    "\n",
    "        axes.set_title(f\"Wykres pudełkowy dla zmiennej {floatFeature}\")\n",
    "\n",
    "\n",
    "def NarysujSkrzypce(Dataset:pd.DataFrame, FloatFeatures:list[str], Condition:str | None = None) -> None:\n",
    "     \"\"\"Ta funkcja rysuje wykresy skrzypcowe dla zmiennych ciągłych.\n",
    "    1) Dataset - oryginalny zestaw danych.\n",
    "    2) FloatFeatures - zmienne numeryczne\n",
    "    3) Condition = Pewna zmienna kategoryczna, za pomocą której stworzą się warunkowe wykresy skrzypcowe ze względu przynależność do klasy.\"\"\"\n",
    "\n",
    "     for floatFeature in FloatFeatures:\n",
    "        figure = plt.figure(num = f\"VIOLIN_plot_{floatFeature}\")\n",
    "        axes = figure.add_subplot()\n",
    "\n",
    "        sns.violinplot(Dataset, x = floatFeature, hue = Condition)\n",
    "\n",
    "        axes.set_title(f\"Wykres skrzypcowy dla zmiennej {floatFeature}\")\n",
    "\n",
    "        axes.legend([])\n",
    "\n",
    "        axes.grid(True, alpha = 0.6)\n",
    "        axes.spines[['top','right']].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "def NarysujWykresParowy(Dataset:pd.DataFrame,  Condition: str | None = None) -> None:\n",
    "    \"\"\"Funkcja rysuje wykres parowy dla wszystkich par zmiennych ciągłych.\n",
    "    \"\"\"\n",
    "    sns.pairplot(Dataset, hue = Condition,diag_kind = \"kde\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ZakodujDane(Dataset:pd.DataFrame, CatFeatures:list[str], NumFeatures:list[str]) -> pd.DataFrame:\n",
    "#     \"\"\"Funkcja koduje  zmienne niezależne kategoryczne za pomocą transformatora OHE.\"\"\"\n",
    "#     cat_col_transformer = ColumnTransformer(transformers = \n",
    "#                                             [('OHE',OneHotEncoder(sparse_output = False), CatFeatures)],\n",
    "#                                             remainder = \"passthrough\",)\n",
    "    \n",
    "#     #Przekształć zmienną X za pomocą określonego wyżej transformatora. \n",
    "#     X_coded = cat_col_transformer.fit_transform(X = Dataset)\n",
    "    \n",
    "#     CatFeatures_coded = cat_col_transformer.named_transformers_[\"OHE\"].get_feature_names_out(input_features = CatFeatures,)\n",
    "\n",
    "#     Dataset_coded = pd.DataFrame(data = X_coded, columns =  np.concatenate((CatFeatures_coded, NumFeatures)))\n",
    "    \n",
    "#     return Dataset_coded\n",
    "\n",
    "\n",
    "\n",
    "# def TransformujDane(X: pd.DataFrame,  numpredictors:list[str], pca_predictors:list[str]) -> tuple[ np.ndarray, ColumnTransformer]:\n",
    "#     \"\"\"Funkcja stosuje standaryzacje dla tablicy, która zawiera już zmienne będące liczbami.\n",
    "#     Numpredictors to zmienne, które zostaną poddane procesowi standaryzacji. pca_predictors to cechy, dla których składowe główne zostaną wyliczone\"\"\"\n",
    "#     col_transformer = ColumnTransformer(transformers = [(\"Scaler\", StandardScaler(), numpredictors) ,\n",
    "#                                                              ('PCA', PCA(n_components = 1), pca_predictors)], remainder = \"passthrough\")\n",
    "\n",
    "\n",
    "#     return col_transformer.fit_transform(X = X),  col_transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definicja modeli z hiperparametrami\n",
    "Models = {\n",
    "    \"DrzewkoDecyzyjne\": DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", min_samples_split=10), \n",
    "    \"LasLosowy\": RandomForestClassifier(n_estimators=15, criterion='gini'), \n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"RegresjaLiniowa\": MultiOutputRegressor(estimator = LinearRegression()),\n",
    "    \"RegresjaLogistyczna\": LogisticRegression()\n",
    "}                \n",
    "\n",
    "# #Słownik do przechowywania hiperparametrów modeli:\n",
    "# Models_hipparams = {\"DrzewkoDecyzyjne\":{\"criterion\":['gini','entropy'],\n",
    "#                                         \"splitter\":['best','random'],\n",
    "#                                         \"min_samples_split\":[2,3,4],\n",
    "#                                         \"min_samples_leaf\":[2,3,4]},\n",
    "\n",
    "#                     \"LasLosowy\":{\"n_estimators\":list(range(5, 50, 5)),\n",
    "#                                   \"criterion\":['gini','entropy'],\n",
    "#                                         \"min_samples_split\":[3,3,4],\n",
    "#                                          \"min_samples_leaf\":[2,3,4]},\n",
    "                                        \n",
    "#                     \"KNN\": {\"n_neighbors\":list(range(1, 10, 1)),\n",
    "#                             \"p\":[1,2]},\n",
    "                            \n",
    "#                         \"RegresjaLogistyczna\": {\n",
    "#                             \"penalty\":['l1','l2'],\n",
    "#                              \"solver\":['lbfgs','liblinear','newton-cg',],\n",
    "#                              'multi_class':['auto','ovr','multinomial']\n",
    "#                         }\n",
    "#                             }\n",
    "\n",
    "\n",
    "#Słownik do przechowywania hiperparametrów modeli:\n",
    "Models_hipparams = {\"DrzewkoDecyzyjne\":{\"criterion\":['gini'],\n",
    "                                        \"splitter\":['best'],\n",
    "                                        \"min_samples_split\":[2],\n",
    "                                        \"min_samples_leaf\":[2]},\n",
    "\n",
    "                    \"LasLosowy\":{\"n_estimators\":list(range(5, 11, 5)),\n",
    "                                  \"criterion\":['gini','entropy'],\n",
    "                                        \"min_samples_split\":[2],\n",
    "                                         \"min_samples_leaf\":[2]},\n",
    "                                        \n",
    "                    \"KNN\": {\"n_neighbors\":list(range(1, 3, 1)),\n",
    "                            \"p\":[1]},\n",
    "                            \n",
    "                        \"RegresjaLogistyczna\": {\n",
    "                            \"penalty\":['l1','l2'],\n",
    "                             \"solver\":['lbfgs'],\n",
    "                             'multi_class':['auto']\n",
    "                        }, \"RegresjaLiniowa\":{}\n",
    "                            }\n",
    "\n",
    "\n",
    "\n",
    "def TrainAndTestModelStat(Model, X_train:pd.DataFrame, y_train:pd.DataFrame, X_test:pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Funkcja trenuje model za pomocą danyc treningowych (X_train, y_train), a następnie dokonuje predyckcji etykiet klasy docelowej i zwraca przewidywane etykietki.\n",
    "    Jeżeli model jest regresją liniową, przewidziane etykietki są tablicą wymiaru (n_test, n_outputs), gdzie n_outputs to liczba klas emisji.\n",
    "    W przeciwnym wypadku  etykietki są wymiaru (n_test, 1)\"\"\"\n",
    "    Model.fit(X = X_train, #Znajdź optymalne parametry dla danego Modelu, eksponując model na dane treningowe.\n",
    "              y = y_train) \\\n",
    "\n",
    "    return Model.predict(X_test) # Dokonaj przewidywań etykietki klas. Nie zwracamy od razu metryki dokładności. Przewidziane etykietki pomogą nam metrykę policzyć oraz ułatwią\n",
    "                                 #stworzenie macierzy pomyłek. \\\n",
    "\n",
    "\n",
    "\n",
    "def ComputeAccuracy(TruevsPrediction:pd.DataFrame, n_splits:int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Funkcja, na podstawie tabeli porównań etykiet prawdziwych i przewidywanych, oblicza pewną miarę dokładności (accuracy_score) dla wszystkich modeli i dla wszystkich  powtórzeń.\"\"\"\n",
    "\n",
    "    MetricComparison = np.zeros(shape = [n_splits, len(Models.keys())], \n",
    "                                 dtype = np.float64)\n",
    "    \n",
    "    \n",
    "    for model_indx, model in enumerate(Models.keys()):\n",
    "        for i in range(n_splits):\n",
    "            y_true = TruevsPrediction[(model, i, \"True\")]\n",
    "            y_pred = TruevsPrediction[(model, i, \"Pred\")]\n",
    "\n",
    "            perfomance_metric = accuracy_score(y_true = y_true, \n",
    "                                               y_pred = y_pred)\n",
    "\n",
    "            MetricComparison[i, model_indx] = perfomance_metric\n",
    "\n",
    "    return pd.DataFrame(data = MetricComparison, \n",
    "                                     columns = list(Models.keys()))\n",
    "\n",
    "\n",
    "\n",
    "def ComputeMetric(TruevsPrediction:pd.DataFrame, metric) -> pd.DataFrame:\n",
    "    \"\"\"Funkcja wylicza precyzje albo wrażliwość albo f1\"\"\"\n",
    "    MetricComparison = np.zeros(shape = [n_splits, len(Models.keys())], \n",
    "                                 dtype = np.float64)\n",
    "    \n",
    "    for model_indx, model in enumerate(Models.keys()):\n",
    "        for i in range(n_splits):\n",
    "            y_true = TruevsPrediction[(model, i, \"True\")]\n",
    "            y_pred = TruevsPrediction[(model, i, \"Pred\")]\n",
    "\n",
    "            perfomance_metric =  metric(y_true =y_true,\n",
    "                                                  y_pred = y_pred, \n",
    "                                                  average = \"weighted\",)\n",
    "\n",
    "            MetricComparison[i, model_indx] = perfomance_metric\n",
    "\n",
    "\n",
    "    return pd.DataFrame(data = MetricComparison, \n",
    "                                     columns = list(Models.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotlineScores(perfomance_df: pd.DataFrame, metric_name:str, n_splits:int, params_type:str = \"bez strojenia\") -> None:\n",
    "    \"\"\"Stwórz wykresy liniowe obrazujące dynamikę zmian dokładności modeli.\"\"\"\n",
    "    figure = plt.figure()\n",
    "    axes = figure.add_subplot()\n",
    "    \n",
    "    x_values:list[int] = list(range(0,n_splits))\n",
    "\n",
    "   \n",
    "    for model_name in Models.keys():\n",
    "        axes.plot(x_values, \n",
    "                  perfomance_df[model_name])\n",
    "    \n",
    "    #Tablica, która przechowuje mediane wartości metryki dokładności w i-tym podziale.\n",
    "    averages:list[float] = []\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        averages.append(perfomance_df.iloc[i, :].median())\n",
    "    \n",
    "    axes.plot(x_values, averages, linestyle = \"dashed\", linewidth = 4)\n",
    "\n",
    "    axes.legend(list(Models.keys()) +[\"MetricMedian\"])\n",
    "    axes.set_title(f\"Dynamika zmian metryki {metric_name} dla modeli, wersja {params_type}\")\n",
    "\n",
    "    axes.set_xlabel(\"Numer iteracji\") #Ustaw ładną etykietkę osi Ox\n",
    "    axes.set_ylabel(f\"{metric_name}\") #Ustaw ładną etykietkę osi Oy\n",
    "\n",
    "    axes.set_xticks(x_values) #Ustaw wartości tyknięć na osi Ox\n",
    "    \n",
    "    axes.grid(True) #Dodaj linie siatki\n",
    "\n",
    "\n",
    "    axes.spines[['top','right']].set_visible(False) #Usuń kreskę górną oraz dolną.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def PlotConfussionMatrices(model_name:str, y_true:np.ndarray, y_predicted: np.ndarray, type:str = \"bez strojenia\"):\n",
    "    \"\"\"Funkcja ta rysuje macierz pomyłek dla  danego modelu. \n",
    "        1) y_true  są etykietkami rzeczywistymi\n",
    "        2) y_predicted są etykietkami przewidzianymi\n",
    "        3) type jest to typ strojenia parametrów. Może być ten tryb statyczny (wtedy piszemy type = \"stat\") albo dynamiczny (wtedy piszmey type = \"dyna\")\n",
    "        \"\"\"\n",
    "    axes = plt.figure(num = f\"{model_name}_conf_matrix_{type}\").add_subplot()\n",
    "\n",
    "\n",
    "    cos = ConfusionMatrixDisplay.from_predictions(y_true = y_true, y_pred = y_predicted, ax = axes, normalize = \"true\")\n",
    "    axes.set_title(f\"ConfMatrix dla  modelu {model_name}, wersja {type}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MacierzPomylek(TrueVSPrediction:pd.DataFrame, n_splits:int, type:str = \"bez strojenia\"):\n",
    "    \"\"\"Funkcja wylicza macierze pomyłek dla wszystkich modeli, a następnie obrazuje te macierze na wykresie.\n",
    "    1) TrueVSPrediction: macierz zawierająca etykietki przewidywane oraz rzeczywiste\n",
    "    2) Liczba podziałów zbioru dataset na zbiór treningowy i testowy.\n",
    "    3) type = rodzaj strojenia parametrów (statyczny albo dynamiczny)\"\"\"\n",
    "\n",
    "    for model_name in Models.keys():\n",
    "        y_true = TrueVSPrediction[(model_name, 0, \"True\")] #Znajdź kolumnę prawdziwcych etykiet.\n",
    "        y_pred = TrueVSPrediction[(model_name, 0, \"Pred\")] #Znajdź kolumne przewidywanych etykiet.\n",
    "        \n",
    "        PlotConfussionMatrices(model_name, y_true, y_pred, type) #Narysuj macierz pomyłek.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def StworzTabelkePorównawczą() -> pd.DataFrame:\n",
    "    global Models, n_splits\n",
    "    \"\"\"Funkcja stwarza tabelkę porównawcza, która jest po prostu ramką pandas. Indeksy kolumn są trzypoziomowe. Na najwyższym poziomie jest nazwa modelu, niżej jest\n",
    "    numer podziału, a na końcu tyb etykiet (prawdziwe etykiety lub prawdziwe etykiety)\"\"\"\n",
    "\n",
    "\n",
    "    Indeces = pd.MultiIndex.from_product( [list(Models.keys()), range(n_splits), [\"True\", \"Pred\"] ] #Stwórz  hierarchiczny system indeksów dla kolumn.\n",
    "                                        ,names = [\"Model\", \"iter_no\", \"array_type\"]) #Nadaj poszczególnym poziomom wyjaśnialne i sensowne nazwy.\n",
    "\n",
    "    return  pd.DataFrame(data = None, \n",
    "                                    columns = Indeces)\n",
    "\n",
    "def PorównajZIBeZStrojeniaModel(Metric_comparison_stat:pd.DataFrame, Metric_comparison_dyna:pd.DataFrame, metric_name:str,\n",
    "                           n_splits:int) -> None:\n",
    "    \"\"\"Funkcja porónuje wartości metryk dokładności dla stojonych i niestrojonych modeli indywidualnie.\"\"\"\n",
    "    global Models\n",
    "\n",
    "    models_name: list[str] = list(Models.keys()) #Znajdź listę nazw modeli.\n",
    "\n",
    "    x_values:list[int] = list(range(1, n_splits+1))\n",
    "\n",
    "    for model_name in models_name:\n",
    "        #Stwórz okienko, na którym będzie wyświetlane porównanie między niedostrojonym, a dostrojonym modelem.\n",
    "        okno: plt.figure = plt.figure( num = f\"{model_name} (un)tuned metric comparison for {metric_name}\")\n",
    "        #Stwórz osie.\n",
    "        osie = okno.add_subplot()\n",
    "\n",
    "    \n",
    "        M_untuned:pd.Series = Metric_comparison_stat[model_name] \n",
    "        M_tuned: pd.Series = Metric_comparison_dyna[model_name]\n",
    "     \n",
    "        osie.plot(x_values,  M_untuned)\n",
    "        osie.plot(x_values, M_tuned)\n",
    "\n",
    "        osie.legend([\"Niedostrojony\",'Dostrojony'])\n",
    "\n",
    "\n",
    "        osie.grid(True)\n",
    "        osie.spines[['top','right']].set_visible(False)\n",
    "        osie.set_title(f\"Porównanie niestrojonego i strojonego {model_name}, metryka {metric_name}\")\n",
    "\n",
    "        osie.set_xlabel(\"Numer powtórzenia\")\n",
    "        osie.set_ylabel(f\"Wartość metryki {metric_name}\")\n",
    "        osie.set_xticks(x_values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie metody porównaczej.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class TrainTestModels():\n",
    "    def __init__(self,Dataset:pd.DataFrame, target_var_disc:str, Cat_features:list[str], Num_features:list[str], Models:dict[str, \"estimator\"], Models_hipparams:dict[str, dict],\n",
    "                 n_splits:int = 5, train_size:float = 0.8, test_size:float = 0.2, Cat_predictors:list[str]  = [], Num_predictors:list[str] = [], PCA_predictors:list[str]= []) -> None:\n",
    "        \"\"\"Konstruktor klasy, która trenuje modele. \n",
    "        Opis argumentów konstruktora:\n",
    "        ---------\n",
    "        Dataset: pd.DataFrame - Ramka danych typu pandas, która przechowuje zmienne objaśniające i zmienną objaśnianą. \\n\n",
    "        target_var_disc:str - Nazwa zmiennej objaśnianej. \\n\n",
    "        Cat_features:list[str] - Lista zmiennych kategorycznych. \\n\n",
    "        Num_features:list[str] - Lista zmiennych numerycznych. \\n\n",
    "        Cat_predictors:list[str] - Lista predyktorów kategorycznych. Predyktory kategoryczne nie zostały jeszcze zakodowane. \\n\n",
    "        Num_predictors:list[str] - Lista predyktorów numerycznych. \\n\n",
    "        PCA_predictors:list[str] - Lista predyktorów, które mają ulec analizie składowych głównych.\n",
    "        Models:dict[str, \"Estimator\"] - Słownik, którego wartościami są instancje modeli, które chcemy wytrenować. Kluczami są umowne nazwy modeli. \\n\n",
    "        Models_hipparams:dict[str, dict] - Słownik, którego kluczami są umowne nazwy modeli, a którego wartościami są siatki parametrów danego modelu. \\n\n",
    "        n_splits:int - Liczba podziałów na zbiór treningowy i testowy. \\n\n",
    "        train_size:float - Odsetek obserwacji treningowych. \\n\n",
    "\n",
    "        test_size:float - Odsetek obserwacji testowych. \\n\n",
    "        ---------\n",
    "        \"\"\"\n",
    "        self.Dataset:pd.DataFrame = Dataset \n",
    "        \n",
    "        self.Cat_features = Cat_features\n",
    "        self.Num_features = Num_predictors\n",
    "\n",
    "        self.target_var_discr:str = target_var_disc\n",
    "        self.Cat_predictors:list[str] = Cat_predictors\n",
    "        self.Num_predictors:list[str] = Num_predictors\n",
    "        self.PCA_predictors:list[str] = PCA_predictors\n",
    "\n",
    "        self.Models:dict[str, \"estimator\"] = Models\n",
    "        self.Models_hipparams:dict[str, dict] = Models_hipparams\n",
    "\n",
    "        self.n_splits:int = n_splits\n",
    "        self.train_size:float = train_size\n",
    "        self.test_size:float = test_size\n",
    "\n",
    "\n",
    "        self.PrzygotujRamkiPorownawcze()\n",
    "        \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def StworzRamkePorownawcza(Models: dict[str, \"estimator\"], n_splits:int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Funkcja stwarza tabelkę porównawcza, która jest po prostu ramką pandas. Indeksy kolumn są trzypoziomowe. Na najwyższym poziomie jest nazwa modelu, niżej jest\n",
    "        numer podziału, a na końcu tyb etykiet (prawdziwe etykiety lub przewidywane etykiety).  \\n \n",
    "        Opis argumentów: \n",
    "        ---------\n",
    "        Models:dict[str, \"estimator\"] - Słownik, którego wartościami są instancje modeli, które trenujemy, a którego kluczami są umowne nazwy modeli. \\n\n",
    "        n_slits:int - Liczba podziałów zbioru na zbiór uczący i zbiór testowy. \\n.\n",
    "        ---------\n",
    "        \"\"\"\n",
    "\n",
    "        Indeces = pd.MultiIndex.from_product( [list(Models.keys()), range(n_splits), [\"True\", \"Pred\"] ] #Stwórz  hierarchiczny system indeksów dla kolumn.\n",
    "                                            ,names = [\"Model\", \"iter_no\", \"array_type\"]) #Nadaj poszczególnym poziomom wyjaśnialne i sensowne nazwy.\n",
    "\n",
    "        return  pd.DataFrame(data = None,  columns = Indeces)\n",
    "\n",
    "\n",
    "    def PrzygotujRamkiPorownawcze(self,) -> None:\n",
    "        \"\"\"Ta metoda dla każdego rodzaju modeli (niestrojony, strojony, strojony+fs) tworzy ramki porównawcze.\"\"\"\n",
    "\n",
    "        self.FactVsPrediction_untuned:pd.DataFrame =  TrainTestModels.StworzRamkePorownawcza(Models = self.Models, n_splits = n_splits)\n",
    "        self.FactVsPrediction_tuned:pd.DataFrame = TrainTestModels.StworzRamkePorownawcza(Models = self.Models, n_splits = n_splits)\n",
    "        self.FactVsPrediction_FS:pd.DataFrame = TrainTestModels.StworzRamkePorownawcza(Models = self.Models, n_splits = n_splits)\n",
    "\n",
    "\n",
    "\n",
    "    def ZakodujZmienneKategoryczne(self , X:pd.DataFrame, Cat_predictors:list[str], Num_predictors:list[str]) -> pd.DataFrame:\n",
    "        \"\"\"Funkcja koduje  zmienne niezależne kategoryczne za pomocą transformatora OHE.\n",
    "        Opis argumentów:\n",
    "        ---------\n",
    "        X:pd.DataFrame - Zbiór danych z predyktorami. \\n\n",
    "        Cat_predictors:list[str] - Lista predyktorów kategorycznych. \\n\n",
    "        Nun_predictors:list[str] - Lista predyktoró numerycznych. \\n\n",
    "\n",
    "\n",
    "        Co funkcja zwraca:\n",
    "        Zbiór danych, którego predyktory kategoryczne zostały zakodowane metodą OHE.\n",
    "        \"\"\"\n",
    "        cat_col_transformer = ColumnTransformer(transformers = \n",
    "                                                [('OHE',  OneHotEncoder(sparse_output = False), Cat_predictors)],\n",
    "                                                remainder = \"passthrough\",)\n",
    "        \n",
    "\n",
    "        #Przekształć zmienną X za pomocą określonego wyżej transformatora. \n",
    "        X_coded:np.ndarray = cat_col_transformer.fit_transform(X = X)\n",
    "\n",
    "        #Znajdź nowe nazwy zmiennych kategorycznych.\n",
    "        CatFeatures_coded:list[str] = cat_col_transformer.named_transformers_[\"OHE\"].get_feature_names_out(input_features = Cat_predictors,) \n",
    "\n",
    "        return pd.DataFrame(data = X_coded, columns =  np.concatenate((CatFeatures_coded, Num_predictors)))\n",
    "         \n",
    "    \n",
    "    \n",
    "    def TransformujZmienneNumeryczne(self, X: pd.DataFrame,  Num_predictors:list[str], PCA_predictors:list[str]) -> tuple[ np.ndarray, ColumnTransformer]:\n",
    "        \"\"\"Funkcja aplikuje transformacje na predyktorach numerycznych (skalowanie standardowe, analiza składowych głównych)\n",
    "        Opis argumentów:\n",
    "        X:pd.DataFrame - Treningowy zbiór danych z predyktorami. \\n\n",
    "        Nun_predictors:list[str] - Lista predyktoró numerycznych. \\n\n",
    "        PCA_predictors:list[str] - Lista predyktorów dla których ma zostać wykonana analiza składowych głównych.\n",
    "\n",
    "        Co funkcja zwraca:\n",
    "        Przekształcony zbiór predyktorów oraz wytrenowany transformator.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        No_PCA_num_predictors:list[str] = [var for var in Num_predictors if var not in PCA_predictors] #Znajdź zmienne numeryczne, których nie poddajemy procesowi analizy składowych głównych.\n",
    "\n",
    "        Num_transformer:Pipeline = Pipeline(steps = [(\"Scalling\", StandardScaler())]) #Rurociąg dla niePCA predyktorów\n",
    "        PCA_transformer: Pipeline = Pipeline( steps = [ (\"Scalling\", StandardScaler(), ),  #Rurociąg dla predyktorów PCA\n",
    "                                                       (\"PCA\",  PCA(n_components = 0.9))     ])\n",
    "\n",
    "        #Zdefiniuj rownoległy transformator dla kolumn PCA  i kolumn niePCA\n",
    "        col_transformer: ColumnTransformer = ColumnTransformer(transformers = \n",
    "                                                               [(\"Num_trans\", Num_transformer, No_PCA_num_predictors),\n",
    "                                                                               (\"PCA\", PCA_transformer, PCA_predictors)],\n",
    "                                                                               remainder = \"passthrough\")\n",
    "                                 \n",
    "        #Wytrenuj kolumnowy_transformator                                                                \n",
    "        col_transformer.fit(X = X)\n",
    "\n",
    "        X_transformed:np.ndarray = col_transformer.transform(X = X)\n",
    "        \n",
    "        return X_transformed,  col_transformer\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def TrenujTestujManualnie(self, X:pd.DataFrame, y:pd.Series, train_indx:np.ndarray, test_indx:np.ndarray) -> None:\n",
    "        \"\"\"Ta metoda trenuje i testuje modele uczenia maszynowego za pomocą ręcznie dobranych predyktorów.\n",
    "        Opis argumentów:\n",
    "        X:pd.DataFrame - Zbiór predyktorów\n",
    "        y:pd.Series - Zmienna docelowa\n",
    "        train_indx:np.ndarray - Zbiór indeksów treningowych\n",
    "        test_indx: np.ndarray - Zbiór indeksów testowychc.\n",
    "        \"\"\"\n",
    "        X_encoded:pd.DataFrame = self.ZakodujZmienneKategoryczne(X = X, \n",
    "                                           Cat_predictors = self.Cat_predictors,\n",
    "                                            Num_predictors = self.Num_predictors)\n",
    "        \n",
    "\n",
    "        for model_name in self.Models.keys():\n",
    "            model: 'estimator' = self.Models[model_name] #Instancja danego modelu.\n",
    "\n",
    "            \n",
    "            model_hipparams: dict[str, dict] = self.Models_hipparams[model_name] #Siatka hiperparametrów modelu.\n",
    "\n",
    "            if model_name != \"RegresjaLiniowa\":\n",
    "                X_train:pd.DataFrame = X_encoded.iloc[train_indx, :] #Treningowy zbiór predyktorów, którego kategoryczne zmienne zostały zakodowane.\n",
    "                X_test:pd.DataFrame = X_encoded.iloc[test_indx, :] #Testowy zbiór predyktorów, którego kategoryczne zmienne zostały zakodowane.\n",
    "        \n",
    "\n",
    "                y_train:pd.Series = y[train_indx] #Testowy zbiór zmiennej docelowej.   \n",
    "                y_test:pd.Series = y[test_indx] #Testowy zbiór zmiennej docelowej.\n",
    "                print(X_train.shape, \"Próba przed \\n\")\n",
    "\n",
    "                #Zdobądź przekształcony zbiór treningowy oraz transformator kolumn, który został na nim wytrenowany.\n",
    "                X_train, Transformator = self.TransformujZmienneNumeryczne(X = X_train, \n",
    "                                                                           Num_predictors = self.Num_predictors, \n",
    "                                                                           PCA_predictors = self.PCA_predictors)\n",
    "                \n",
    "                X_test = Transformator.transform(X = X_test)\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "    def PodzielZbiorDanych(self):\n",
    "        \"\"\"\"Funkcja wydobywa indeksy treningowe i indeksy testowe w n_splits podziałach, które następnie przekazuje do metody TrenujTestujManualnie\"\"\"\n",
    "        #Zdefiniuj stratyfikowany podział szufladkowy.\n",
    "        SSS_inst: StratifiedShuffleSplit = StratifiedShuffleSplit(n_splits = self.n_splits, \n",
    "                                                                  test_size = self.test_size, \n",
    "                                                                  train_size = self.train_size)\n",
    "        \n",
    "        self.X:pd.DataFrame = self.Dataset[ self.Cat_predictors + self.Num_predictors] #Ramka danych zawierająca predyktory, które nie zostały poddane obróbce wstępnej.\n",
    "        self.y:pd.DataFrame = self.Dataset[self.target_var_discr] #Zdyskretyzowana zmienna docelowa.\n",
    "\n",
    "\n",
    "        iter_indx:int  #Zmienna, która wskazuje na numer powtórzenia pętli.\n",
    "        indx_tup: tuple[np.ndarray, np.ndarray] #Dwuelementowa krotka, która zawiera indeksy treningowe oraz indeksy testowe.\n",
    "\n",
    "        for iter_indx, indx_tup in enumerate(SSS_inst.split(X = self.X, y = self.y)):\n",
    "            train_indx:np.ndarray #Indeksy treningowe. \n",
    "            test_indx:np.ndarray  #Indeksy testowe.\n",
    "\n",
    "            train_indx, test_indx = indx_tup\n",
    "\n",
    "            self.TrenujTestujManualnie(X = self.X, y = self.y, \n",
    "                                       train_indx = train_indx, test_indx = test_indx)\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def TrenujTestujModele(X:pd.DataFrame, y:pd.DataFrame, y_OHE:np.ndarray, cat_predictors:list[str], num_predictors:list[str],\n",
    "                       Models:dict[str, \"estimator\"], Models_hipparams:dict[str,  dict ], n_splits:int = 5, train_size:float = 0.8, test_size:float = 0.2) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "\n",
    "    \n",
    "    TrueVSPrediction_stat:pd.DataFrame = StworzTabelkePorównawczą() #Wersja niestrojona\n",
    "    TrueVSPrediction_dyna:pd.DataFrame = StworzTabelkePorównawczą() #Wersja strojona\n",
    "                                                        #Wersja featureselection + tuning\n",
    "    \n",
    "    TrueVSPrediction_fs: pd.DataFrame = StworzTabelkePorównawczą()\n",
    "\n",
    "    SSS = StratifiedShuffleSplit(n_splits = n_splits, train_size = train_size, test_size  = test_size)\n",
    "   \n",
    "\n",
    "    for iter_indx, indx in enumerate(SSS.split(X = X, y = y )): #Wydobadź indeksy treningowe i testowe.\n",
    "        train_indx, test_indx = indx #Znajdź indeksy treningowe oraz indeksy testowe.\n",
    "    \n",
    "        X_train =  X.iloc[train_indx, ]\n",
    "        X_test = X.iloc[test_indx, ]\n",
    "    \n",
    "    \n",
    "        X_train ,Scaler = TransformujDane(X_train, numpredictors = num_predictors, pca_predictors= [\"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\",\n",
    "                                                                                   \"Fuel Consumption Comb (L/100 km)\",\"Fuel Consumption Comb (mpg)\"])\n",
    "        X_test = Scaler.transform(X_test) #Dokonaj skalowania na zbiorze testowym za pomocą parametrów wydobytych ze zbioru treningowego.\n",
    "\n",
    "    \n",
    "        for model_name in Models.keys():\n",
    "            model:'Estimator' = Models[model_name] #Zrekrutuj model.\n",
    "            model_hiperparams = Models_hipparams[model_name] #Wydobądź siatek hiperparametrów do przeszukania.\n",
    "            \n",
    "            if model_name != \"RegresjaLiniowa\":\n",
    "                y_train = np.array(y.iloc[train_indx, :]).ravel()\n",
    "                y_test =  np.array(y.iloc[test_indx, :]).ravel()\n",
    "\n",
    "                #Statyczne dobieranie hiperparametrów.\n",
    "                y_pred_stat: np.ndarray = TrainAndTestModelStat(model, X_train, y_train, X_test) #Etykietki przewidziane.\n",
    "\n",
    "\n",
    "                #Miejsce na dynamiczne strojenie parametrów.\n",
    "                GridSearch = GridSearchCV(estimator = model, param_grid = model_hiperparams)\n",
    "                fitted_model = GridSearch.fit(X = X_train, y = y_train) #To jest instancja modelu z najbardziej optymalnymi hiperparametrami.\n",
    "\n",
    "                #Znajdź predyktowane etykietki\n",
    "                y_pred_dyna:np.ndarray = fitted_model.predict(X_test)\n",
    "\n",
    "\n",
    "                #Doklej etykietki przewidziane do ramki danych porównującej statycznie-strojone modele.\n",
    "                TrueVSPrediction_stat[(model_name, iter_indx, \"True\")] = y_test\n",
    "                TrueVSPrediction_stat[(model_name, iter_indx, \"Pred\")] = y_pred_stat\n",
    "\n",
    "\n",
    "                #Doklej etykietki przewidziane do ramki danych porównującej dynamicznie-strojone modele.\n",
    "                TrueVSPrediction_dyna[(model_name, iter_indx, \"True\")] = y_test\n",
    "                TrueVSPrediction_dyna[(model_name, iter_indx, \"Pred\")] = y_pred_dyna\n",
    "\n",
    "\n",
    "            else:\n",
    "                #Regresja liniowa niestety ma wielowymiarowe-wyjście.\n",
    "                y_train = y_OHE[train_indx] #Weź etykietki docelowe treningowe.\n",
    "                y_test = y_OHE[test_indx].argmax(axis = 1) #Weź etykietki docelowe testowe.\n",
    "\n",
    "                #Znajdź predyktowane etykietki\n",
    "                y_pred: np.ndarray = TrainAndTestModelStat(model, X_train, y_train, X_test).argmax(axis = 1) \n",
    "                \n",
    "\n",
    "                #Doklej etykietki przewidziane do ramki danych porównującej statycznie-strojone modele.\n",
    "                TrueVSPrediction_stat[(model_name, iter_indx, \"True\")] = y_test\n",
    "                TrueVSPrediction_stat[(model_name, iter_indx, \"Pred\")] = y_pred\n",
    "\n",
    "\n",
    "                #Doklej etykietki przewidziane do ramki danych porównującej dynamicznie-strojone modele.\n",
    "                TrueVSPrediction_dyna[(model_name, iter_indx, \"True\")] = y_test\n",
    "                TrueVSPrediction_dyna[(model_name, iter_indx, \"Pred\")] = y_pred\n",
    "\n",
    "            print(f\"{model_name} {iter_indx}\")\n",
    "\n",
    "         \n",
    "            #Miejsce na strojenie modeli wraz z wyborem cech\n",
    "            SFS_inst = SFS(estimator = model, n_features_to_select = X.shape[1]//10, direction = \"forward\")\n",
    "\n",
    "            Rura: Pipeline = Pipeline(steps = [      (\"SFS\", SFS_inst ),    (model_name, model)      ])\n",
    "                                                                    #Wyciągasz wartości parametru \"param\" dla modelu \"model_name\"\n",
    "            model_hiperparams_fs = { f\"{model_name}__{param}\": model_hiperparams[param] for param in model_hiperparams.keys() }\n",
    "\n",
    "            GridSearch_FS = GridSearchCV(estimator = Rura, param_grid = model_hiperparams_fs)\n",
    "\n",
    "            fitted_model_fs =  GridSearch_FS.fit(X = X_train, y = y_train)\n",
    "\n",
    "            #Znajdź predyktowane etykietki\n",
    "            y_pred_fs:np.ndarray = fitted_model_fs.predict(X_test)\n",
    "\n",
    "            TrueVSPrediction_fs[(model_name, iter_indx, \"True\")] = y_test\n",
    "            TrueVSPrediction_fs[(model_name, iter_indx, \"Pred\")] = y_pred_fs\n",
    "\n",
    "\n",
    "    return TrueVSPrediction_stat, TrueVSPrediction_dyna, TrueVSPrediction_fs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PorównajModele(TrueVSPrediction_df_stat:pd.DataFrame,\n",
    "                   TrueVSPrediction_df_dyna:pd.DataFrame, \n",
    "                   n_splits:int ) -> None:\n",
    "    \"\"\"Funkcja wylicza miary dokładności dla wszystkich modeli. \n",
    "    Pierwsze dwa argumenty są ramkami danych, których wartościami są prawdziwe lub przewidziane etykietki. \n",
    "    Każda z tych ramek ma wielopoziomy system indeksowania kolumn, który jest postaci: (model_name, iter_indx, type).\n",
    "    model_name jest nazwą danego modelu. iter_indx wskazuje na to, w którym podziale etykietki są przewidziane. type = \"True\" albo type = \"Pred\". \n",
    "    Gdy type = \"True\", etykietki są rzeczywiste, w przeciwnym wypadku są przewidziane.\"\"\"\n",
    "\n",
    "\n",
    "    Miary = {\"Accuracy\" : ComputeAccuracy, \"Precision\":precision_score,\n",
    "             \"Recall\":recall_score, \"F1\": f1_score}\n",
    "    \n",
    "\n",
    "    for miara in Miary.keys():\n",
    "\n",
    "        if miara == \"Accuracy\":\n",
    "            Metric_comparison_stat = Miary[miara](TrueVSPrediction_df_stat) #Wartości metryki dokładności, jeżeli strojenie nie miało miejsca.\n",
    "            Metric_comparison_dyna = Miary[miara](TrueVSPrediction_df_dyna) #Wartości metryki dokładności, jeżeli było strojenie.\n",
    "\n",
    "\n",
    "            PlotlineScores(Metric_comparison_stat, miara, n_splits, \"bez strojenia\")\n",
    "            PlotlineScores(Metric_comparison_dyna, miara, n_splits, \"ze strojeniem\")\n",
    "\n",
    "\n",
    "            \n",
    "        else:\n",
    "            Metric_comparison_stat =  ComputeMetric(TrueVSPrediction_df_stat, metric = Miary[miara])\n",
    "            Metric_comparison_dyna =  ComputeMetric(TrueVSPrediction_df_dyna, metric = Miary[miara])\n",
    "\n",
    "            PlotlineScores(Metric_comparison_stat, miara, n_splits, \"bez strojenia\")\n",
    "            PlotlineScores(Metric_comparison_dyna, miara, n_splits, \"ze strojeniem\")\n",
    "\n",
    "\n",
    "        #Na sam koniec, dla każdego modelu indywidualnie, porównaj jego wersję niedostrojoną i strojoną.\n",
    "        PorównajZIBeZStrojeniaModel(Metric_comparison_stat, Metric_comparison_dyna, \n",
    "                                    metric_name = miara,\n",
    "                                      n_splits = n_splits)\n",
    "     \n",
    "\n",
    "\n",
    "    MacierzPomylek(TrueVSPrediction_df_stat, n_splits) #Wylicz oraz narysuj macierz pomyłek dla statycznego strojenia hiperparametrów\n",
    "    MacierzPomylek(TrueVSPrediction_df_stat, n_splits, type = \"Ze strojeniem\") #Wylicz oraz narysuj macierz pomyłek dla dynamicznego strojenia hiperparametrów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ManualEmissionAnalysis(Filename:str, seperator:str, dec_sep: str, dtypes: dict[str, str], bins:list[float], show_plots: bool = True) -> None:\n",
    "    \"\"\"Wielka analiza danych\"\"\"\n",
    "    global target_var, n_splits, train_size, test_size, Models, Models_hipparams\n",
    "\n",
    "\n",
    "    Dataset, n_rows = ReadDataFrame(Filename, seperator, dec_sep) #Odczytaj zestaw danych oraz liczbę wszystkich obserwacji.\n",
    "    Dataset = Dataset.head(2500)\n",
    "    \n",
    "    Features = Dataset.columns #Znajdź listę wszystkich cech w zbiorze danych.\n",
    "\n",
    "    CatFeatures: list[str] = [feature for feature in Features if dtypes[feature] == \"category\"] #Cechy kategoryczne.\n",
    "    FloatFeatures: list[str] = [feature for feature in Features if dtypes[feature] is np.float64] #Cechy ciągłe.\n",
    "\n",
    "\n",
    "    #RYSOWANIE HISTOGRAMÓW DLA ZMIENNYCH KATEGORYCZNYCH\n",
    "    #Agregacja rządkich klas dla zmiennych kategorycznych.\n",
    "    for CatFeature in CatFeatures:\n",
    "        Histogram:pd.Series = CreateFreqTable(Dataset = Dataset,  #Znajdź histogram unikatowych klas dla zmiennej CatFeature.\n",
    "                                    CatFeature = CatFeature) \n",
    "        \n",
    "        AggregateRarestClasses(Dataset, CatFeature, Histogram) #Zagreguj najrzadzsze klasy.\n",
    "\n",
    "        Histogram_agg:pd.Series = CreateFreqTable(Dataset = Dataset,  #Zagregowany histogram.\n",
    "                                                  CatFeature = CatFeature)\n",
    "        \n",
    "        if show_plots is True:\n",
    "            PlotBarPlot(Histogram_agg, CatFeature)\n",
    "\n",
    "    \n",
    "    #Kasowanie zbędnej obserwacji oraz quasi-id kolumny\n",
    "    Dataset = DeleteFutileColsAndObs(Dataset)\n",
    "\n",
    "    #Dyskretyzacja zmiennej docelowej\n",
    "    target_var_discr = target_var +\"_disc\"\n",
    "\n",
    "    Discretize(Dataset, target_var, target_var_discr = target_var_discr,\n",
    "            bins = bins)\n",
    "\n",
    "\n",
    "    \n",
    "    if show_plots is True: #Narysuj wykresy charakteryzujące (relacje między zmiennymi) oraz (charakterystyki zmiennych) na żądanie.\n",
    "        #RYSOWANIE MACIERZY KORELACJI DLA ZMIENNYCH NUMERYCZNYCH\n",
    "        ComputeAndDrawCorrelationMatrix(Dataset, FloatFeatures)\n",
    "\n",
    "        #RYSOWANIE WYKRESÓW SKRZYPCOWYCH DLA Z MIENNYCH NUMERYCZNYCH\n",
    "        NarysujSkrzypce(Dataset, FloatFeatures)\n",
    "\n",
    "        #Rysowanie wykresu parowego dla zmiennych numerycznych\n",
    "        NarysujWykresParowy(Dataset)\n",
    "\n",
    "      \n",
    "    \n",
    "\n",
    "        target_var_discr_histogram:pd.Series = CreateFreqTable(Dataset, target_var_discr) #Znajdź histogram tabelkowy dla zdyskretyzowanej zmiennej celu.\n",
    "        PlotBarPlot(target_var_discr_histogram, target_var_discr, Showxlabels = True) #Narysuj wykres słupkowy częstotliwości dla zmiennej celu zdyskretyzowanej.\n",
    "\n",
    "\n",
    "        NarysujGęstości(Dataset, FloatFeatures, target_var_discr) #Wykresy gęstości warunkowe\n",
    "        NarysujPudełko(Dataset, FloatFeatures, target_var_discr) #Wykresy pudełkowe warunkowe\n",
    "\n",
    "\n",
    "        NarysujWykresParowy(Dataset, target_var_discr) #Wykresy parowe warunkowe\n",
    "        \n",
    "\n",
    "    #Ustal ostateczny zbiór predyktorów.\n",
    "    Predictors = ['Make', \"Vehicle Class\",'Engine Size(L)','Cylinders','Transmission','Fuel Type',\"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\",\n",
    "                                                                                   \"Fuel Consumption Comb (L/100 km)\",\"Fuel Consumption Comb (mpg)\"]\n",
    "\n",
    "    #Podziel zbiór predyktorów na zmienne numeryczne oraz zmienne kategoryczne odpowiednio.\n",
    "    num_predictors:list[str] = [feature for feature in Predictors if dtypes[feature] is np.float64]\n",
    "    cat_predictors:list[str] = [feature for feature in Predictors if dtypes[feature] == \"category\"]\n",
    "\n",
    "\n",
    "    WielkiEstimator = TrainTestModels(Dataset = Dataset, target_var_disc = target_var_discr, Cat_features = CatFeatures, Num_features = FloatFeatures, \n",
    "                                      Models = Models, Models_hipparams = Models_hipparams, n_splits = 5, train_size = 0.8, test_size = 0.2, Cat_predictors = cat_predictors, \n",
    "                                      Num_predictors = num_predictors, PCA_predictors = [\"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\", \n",
    "                                                                             \"Fuel Consumption Comb (L/100 km)\",\"Fuel Consumption Comb (mpg)\"])\n",
    "    \n",
    "    WielkiEstimator.PodzielZbiorDanych()\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    # X:pd.DataFrame = Dataset[cat_predictors + num_predictors] #Tablica predyktorów.\n",
    "    # y:pd.DataFrame = Dataset[[target_var_discr]] #Zmienna docelowa.\n",
    "\n",
    "    # X_coded:pd.DataFrame = ZakodujDane(X, cat_predictors, num_predictors) #Zakoduj zmienne kategoryczne predykcyjne.\n",
    "\n",
    "     \n",
    "    # y_OHE:np.ndarray = OneHotEncoder(sparse_output = False).fit_transform(X = y) #Zakoduj zmienną docelową jako zbiór k kolumn binarnych. \n",
    "    #                                                                     #Tak zakodowana etykietka przyda się w wielowyjściowej regresji.\n",
    "\n",
    "\n",
    "    # SSS = StratifiedShuffleSplit(n_splits = n_splits,  #Zdefiniuj stratyfikowany podział szufladkowy, tak aby zachować rozkład częstości  klas w zmiennej docelowej.\n",
    "    #                              train_size =train_size, \n",
    "    #                              test_size = test_size)\n",
    "    \n",
    "\n",
    "    # TrueVSPrediction_stat, TrueVSPrediction_dyna, TrueVSPrediction_fs = TrenujTestujModele(X = X_coded, y = y, y_OHE = y_OHE, cat_predictors = cat_predictors,\n",
    "    #                                                                                        num_predictors = num_predictors, Models = Models, Models_hipparams = Models_hipparams, \n",
    "    #                                                                                        n_splits = n_splits, train_size  = train_size, test_size = test_size)\n",
    "\n",
    "\n",
    "                                                                        \n",
    "    #PorównajModele(TrueVSPrediction_stat, TrueVSPrediction_dyna, n_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n",
      "(2000, 90) Próba przed \n",
      "\n",
      "(2000, 87) Próba po \n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_var: str = \"CO2 Emissions(g/km)\" #To jest nazwa zmiennej docelowej.\n",
    "n_splits = 15\n",
    "train_size = 0.75\n",
    "test_size  = 1 - train_size\n",
    "\n",
    "dtypes = { \"Make\": \"category\", #Określ typ danych każdej cechy w ramce danych, która zostanie zaraz odczytana.\n",
    "            \"Model\":\"category\",\n",
    "            \"Vehicle Class\":\"category\",\n",
    "            \"Engine Size(L)\":np.float64,\n",
    "            \"Cylinders\":\"category\",\n",
    "            \"Transmission\":\"category\",\n",
    "            \"Fuel Type\":\"category\",\n",
    "            \"Fuel Consumption City (L/100 km)\":np.float64,\n",
    "            \"Fuel Consumption Hwy (L/100 km)\":np.float64,\n",
    "            \"Fuel Consumption Comb (L/100 km)\":np.float64,\n",
    "            \"Fuel Consumption Comb (mpg)\":np.float64,\n",
    "            \"CO2 Emissions(g/km)\":np.float64}\n",
    "\n",
    "\n",
    "ManualEmissionAnalysis(\"CO2Emission.csv\", ';', ',', dtypes = dtypes,  bins = [150, 200, 300], show_plots = False)\n",
    "\n",
    "\n",
    "# Pytania badawcze przykładowe:\n",
    "# 1) Jak liczba klas docelowych wpływa na skuteczność metod? Czy skuteczność modelu domyślnie maleje, jeżeli liczba klas docelowych wzrośnie?\n",
    "# 2) Jak skuteczne są metody proste w porównaniu z metodami bardziej zaawansowanymi.\n",
    "# 3) Jak istotne jest strojenie parametrów? Czy statyczne strojenie parametrów ulega dynamicznego strojeniu parametrów.\n",
    "# 4) Jak istotny jest wybór optymalnych cech? Czy należy uwzględnić wszystkie względne? A może wystarczy tylko kilka cech?\n",
    "# 5) Jak prezentuje się dokładnośc predykcji w stosunku do poszczególnych klas? Czy klasy rzadsze są łatwiej przewidywalne?\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#Alternatywny dla PCA: MDS, \n",
    "#Dlaczego regresja liniowa jest nieefektywna? Masked class problem.\n",
    "#Porównaj czas uczenia się metod, zarówno dla statycznego strojenia i optymalnego strojenia parametrów.\n",
    "#Prz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co dalej do roboty?:\n",
    "2) Zamknięćie wszystkich funkcji w jedną, potężna funkcję.\n",
    "4) Liczenie wskaźników dokładności, jeżeli selekcja cech była wybierana automatycznie."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
